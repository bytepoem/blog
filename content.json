{"pages":[],"posts":[{"title":"利用 Grafana 以及 node_exporter 中的 tcpstat 收集器监控 TCP 连接各个状态的数量","text":"在经历了 CLOSE_WAIT 增多而导致的服务器性能下降的问题之后，为了能实时监控 TCP 各个状态的数量，我选择了 Grafana 以及 node_exporter 的 tcpstat 收集器。 关于 node_exporter 就不多做介绍了，想详细了解的同学可以访问 Github 上的仓库 👉 Node exporter 。 简单介绍一下 tcpstat 收集器，是 node_exporter 自带的收集器，适用的环境是 Linux，本质是从 /proc/net/tcp 以及 /proc/net/tcp6 获取 TCP 连接状态的信息。需要注意的是当前版本（0.18.1）在高负载下会出现性能问题，具体表现就是采集地址无法访问导致 Prometheus 无法获取数据。另外，tcpstat 收集器是默认不开启，所以启动的时候需要带上 --collector.tcpstat 参数（可以通过参数 -h 了解）。 启动好 node_exporter 并开启 tcpstat 收集器之后，我们就可以前往 Grafana 设置监控面板了。 在新建 panel 中添加一个 Query，查询语句：node_tcp_connection_states{instance=&quot;localhost:9100&quot; 其中 node_tcp_connection_states 是 TCP 连接状态的 metric 的名称，这个怎么来的呢，我是瞎蒙的，因为 Grafana 自带语法提示，所以输入 tcp 就可以直接找到（）。而 9100 就是 node_exporter 的默认端口号。 完整的 Query 就是下面这个样子。 最后查询出来的效果如下： tcpstat 收集器相关的实现在这里 👉 tcpstat_linux.go 。下面贴一下主要代码片段。 首先 tcpstat 定义了 TCP 连接各个状态的常量，即我们可以收集（监控）到的信息。 12345678910111213141516171819202122232425262728const ( // TCP_ESTABLISHED tcpEstablished tcpConnectionState = iota + 1 // TCP_SYN_SENT tcpSynSent // TCP_SYN_RECV tcpSynRecv // TCP_FIN_WAIT1 tcpFinWait1 // TCP_FIN_WAIT2 tcpFinWait2 // TCP_TIME_WAIT tcpTimeWait // TCP_CLOSE tcpClose // TCP_CLOSE_WAIT tcpCloseWait // TCP_LAST_ACK tcpLastAck // TCP_LISTEN tcpListen // TCP_CLOSING tcpClosing // TCP_RX_BUFFER tcpRxQueuedBytes // TCP_TX_BUFFER tcpTxQueuedBytes) 接着定义了收集器的相关信息，比如上边提到的 metric 的名称 node_tcp_connection_states 以及提供的模板变量 state。 12345678910func NewTCPStatCollector(logger log.Logger) (Collector, error) { return &amp;tcpStatCollector{ desc: typedDesc{prometheus.NewDesc( prometheus.BuildFQName(namespace, \"tcp\", \"connection_states\"), \"Number of connection states.\", []string{\"state\"}, nil, ), prometheus.GaugeValue}, logger: logger, }, nil} 下面两个方法就是从 /proc/net/tcp 以及 /proc/net/tcp6 这两个文件获取 TCP 连接状态的信息并转化为 metric。 12345678910111213141516171819202122232425262728293031323334func (c *tcpStatCollector) Update(ch chan&lt;- prometheus.Metric) error { tcpStats, err := getTCPStats(procFilePath(\"net/tcp\")) if err != nil { return fmt.Errorf(\"couldn't get tcpstats: %s\", err) } // if enabled ipv6 system tcp6File := procFilePath(\"net/tcp6\") if _, hasIPv6 := os.Stat(tcp6File); hasIPv6 == nil { tcp6Stats, err := getTCPStats(tcp6File) if err != nil { return fmt.Errorf(\"couldn't get tcp6stats: %s\", err) } for st, value := range tcp6Stats { tcpStats[st] += value } } for st, value := range tcpStats { ch &lt;- c.desc.mustNewConstMetric(value, st.String()) } return nil}func getTCPStats(statsFile string) (map[tcpConnectionState]float64, error) { file, err := os.Open(statsFile) if err != nil { return nil, err } defer file.Close() return parseTCPStats(file)} 本文到这里结束啦，主要介绍了如何利用 Grafana + node_exporter.tcpstat 的方式实时监控 TCP 连接状态信息，如果大家有其他的方式，欢迎下方留言讨论。","link":"/2020/04/21/grafana-tcp-status/"},{"title":"记录一次服务器出现大量 CLOSE_WAIT 的原因排查过程以及解决办法","text":"最近在服务器上发现有大量的 CLOSE_WAIT 存在，排查发现是 Python 爬虫中 requests 导致的。 1. CLOSE WAIT简单来说，TCP 连接断开时需要进行“四次挥手”（建立连接是“三次握手”），TCP 连接的两端都可以发起关闭连接的请求，若其中一端发起了关闭连接，但另外一端没有关闭连接，那么该连接就会处于 CLOSE_WAIT 状态。 四次握手的流程： Client 发送一个 FIN，用来关闭客户端到服务器的数据传送（报文段 1） Server 收到这个 FIN，发回一个 ACK，确认需要为收到的序号加 1（报文段 5）。和 SYN 一样，一个 FIN 占用一个序号 Server 关闭 Client 的连接，发送一个 FIN 给客户端（报文段 6） Client 发回 ACK 报文确认，并将确认序号设为收到的序号加 1（报文段 4） 2. 原因通常来说，CLOSE_WAIT 在服务器停留的时间很短，且只会发生在被动关闭连接的一端。除非 Kill 掉进程，否则它是不会消失的，意味着一直占用资源。如果发现有大量的 CLOSE_WAIT，那就是被动关闭的一方没有及时发送 FIN，一般来说有以下几种可能： 代码问题：请求的时候没有显式关闭 Socket 连接，或者死循环导致关闭连接的代码没有执行到，即 FIN 包没有发出，导致 CLOSE_WAIT 不断累积 响应过慢 / 超时设置过小：双方连接不稳定，一方 Timeout，另外一方还在处理逻辑，导致 Close 被延后 3. 排查查看网络连接首先我们到服务器上看一下网络连接情况。 查看 TCP 连接中各个状态数量可以使用以下命令： netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}' ESTABLISHED 表示正在通信 TIME_WAIT 表示主动关闭 CLOSE_WAIT 表示被动关闭 查看 TCP 连接中 CLOSE_WAIT 的数量可以使用以下命令： netstat -antop | grep CLOSE_WAIT | wc -l netstat 命令用于显示网络状态 -a：显示所有连线中的 Socket -n：直接使用 IP 地址，而不通过域名服务器 -t：显示 TCP 传输协议的连线状况 -o：显示计时器 -p：显示正在使用 Socket 的程序识别码和程序名称 grep 命令用于查找文件里符合条件的字符串 wc 命令用于计算字数 -l：只显示行数 通过以上命令可以看到服务器上的 CLOSE_WAIT 将近 1w2，这还是我重启了部分运行时间较长的爬虫后的数字，重启前高达 4w，这是个不容小觑的潜在问题。 梳理 TCP 连接流向接着我们可以从上图梳理出 CLOSE_WAIT 的连接流向，命令返回里中的 Foreign Address（第 5 栏）代表对方的 IP 地址，即和我们连接着但是却主动关闭了连接的机器，在我这里即是代理池里边的代理。 根据项目数据请求流向还原可能场景然后我们可以根据项目数据请求流向，还原出可能的场景，在我这里即是 CLOSE_WAIT 都发生在本机爬虫、代理以及目标网站的连接上。毕竟 Program name（最后一栏）都写着 Python 了，且这台服务器上只有爬虫用的 Python。 解决思路问题出在爬虫就简单了，唯一会发生网络请求的地方就是使用 requests 模块。 requests 模块会自行处理连接池的问题，且访问完成后出现 CLOSE_WAIT 是正常的，后续会直接复用这些连接。但是如果 CLOSE_WAIT 数量太多且一直下不去，有可能是高并发或者没有关闭的连接一直累积 如果你直接 get 或者 post 的话会每次都创建一个连接池，且这个连接池只会用一次。所以需要通过全局 session 来使用 requests 模块的连接池功能 不是任何时候使用连接池都是有效的，仅当你使用了多线程之类的并发才会有效果。毕竟你是单线程的话，里面是串行，一个线程对应一个连接。此外，我们还可以构造好 HttpAdapter 实例用 session.mount 上。HttpAdapter 的常用参数有以下几种： timeout：超时时间 maxretries：最大尝试次数 pool_connections：最多连接多少个不同的主机，针对每个 Host 都是独立的连接池 pool_maxsize：针对每个主机能创建的最大连接数（底层 TCP），由于一个线程对应一个连接，所以一般有多少个线程指定 pool_maxsize 为多少 使用 requests 模块的时候最好将请求放在 try 中，把可能发生的异常用 except 获取并处理 参考链接： 浅谈 CLOSE_WAIT 又见 CLOSE_WAIT 【原创】python requests 库底层 Sockets 处于 close_wait 状态","link":"/2020/04/20/to-many-close-wait/"},{"title":"在 Spring Boot 中使用 @Crossorign 注解解决跨域问题","text":"最近在 Spring Boot 中写 REST API 时发现前端 Ajax 调用的时候会产生跨域问题。于是乎想到用 jsonp 的方式进行解决，但是发现 AbstractJsonpResponseBodyAdvice 这个类在 Spring Boot 2.0 已经被废弃了，上官网发现有新姿势——《Enabling Cross Origin Requests for a RESTful Web Service》。 1. 浏览器的同源政策同源策略（SOP，Same origin policy） 是由 Netscape 提出的一个著名的安全策略。所有支持 JavaScript 的浏览器都会使用这个策略。所谓同源是指，域名，协议，端口相同。即便两个不同的域名指向同一个 ip 地址，也非同源。 同源策略限制以下几种行为： 1、Cookie、LocalStorage 和 IndexDB 无法读取 2、Dom 和 Js 对象无法获得 3、Ajax 请求不能发送 其目的是为了保证用户信息的安全，防止恶意的网站窃取数据。举个例子： A 网站是一家银行，用户登录以后再去访问 B 网站。如果 B 网站可以读取 A 网站的 Cookie，那么 B 网站就可以利用这些信息为所欲为！（浏览器提交表单不受同源政策的限制）。 2. 跨域解决方案 1、jsonp（只支持 GET 请求） 2、document.domain + iframe 3、location.hash + iframe 4、window.name + iframe 5、postMessage 6、跨域资源共享（CORS） 7、nginx 代理 8、nodejs 中间件代理跨域 9、WebSocket 协议跨域 3. CORSCORS 是一个 W3C 标准，全称是 “跨域资源共享”（Cross-origin resource sharing），是一种允许当前域（domain）的资源（比如 html / js / web service）被其他域（domain）的脚本请求访问的机制（利用 XMLHttpRequest 请求）。由于同源策略，浏览器通常会禁止这种跨域请求。 CORS 请求分为两类：简单请求和非简单请求。 其中满足以下两大条件，就属于简单请求。 请求方法是以下三种方法之一： HEAD GET POST HTTP 的头信息不超出以下几种字段： AcceptAccept-Language Content-Language Last-Event-ID Content-Type：只限于以下三个值 application/x-www-form-urlencoded multipart/form-data text/plain 不满足的为非简单请求。 浏览器对于两种请求的处理是不一样的： 简单请求 浏览器会在简单请求的请求头中添加 Origin 字段，用来说明本次请求来自哪个源（协议 + 域名 + 端口）。服务器判断这个值决定是否通过这次请求 不通过时，返回头则没有 Access-Control-Allow-Origin 字段 通过时，则会多出以下几个字段 123Access-Control-Allow-Origin: http://api.baidu.comAccess-Control-Allow-Credentials: true Access-Control-Expose-Headers: FooBarContent-Type: text/html; charset=utf-8 非简单请求 在正式请求前会发送一个预检请求（OPTIONS） 123OPTIONS /cors HTTP/1.1 Origin: http://api.bob.comAccess-Control-Request-Method:PUT Access-Control-Request-Headers: X-Custom-Header Host: api.baidu.comAccept-Language: en-US Connection: keep-alive User-Agent: Mozilla/5.0... 一旦服务器通过了预检请求，以后每次浏览器正常的 CORS 请求，就都跟简单请求一样，返回头会多一个 Origin 字段以及 Access-Control-Allow-Origin 字段。 4.@Crossorigin 注解全局配置12345678910111213141516171819202122import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.config.annotation.CorsRegistry;import org.springframework.web.servlet.config.annotation.EnableWebMvc;import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;@Configuration@EnableWebMvcpublic class CorsConfig implements WebMvcConfigurer { @Override public void addCorsMappings(CorsRegistry registry) { //设置允许跨域的路径 registry.addMapping(\"/**\") //设置允许跨域请求的域名 .allowedOrigins(\"*\") //是否允许证书 不再默认开启 .allowCredentials(true) //设置允许的方法 .allowedMethods(\"*\") //跨域允许时间 .maxAge(3600); } 局部配置可以注解在整个 Controller 上。 123@CrossOrigin(origins=\"http://localhost:9000\", maxAge=3600)@RestControllerpublic class RestController {} 也可以注解在单个方法上。 12345@CrossOrigin(origins=\"http://localhost:9000\")@GetMapping(\"/hello\")public Greeting greeting() { return \"world\";} 还可以通过 Filter 的方式指定接口。 1234567891011121314@Beanpublic FilterRegistrationBean corsFilter() { UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); CorsConfiguration config = new CorsConfiguration(); config.setAllowCredentials(true); config.addAllowedOrigin(\"http://localhost:9000\"); config.addAllowedOrigin(\"null\"); config.addAllowedHeader(\"*\"); config.addAllowedMethod(\"*\"); source.registerCorsConfiguration(\"/**\", config); // CORS 配置对所有接口都有效 FilterRegistrationBean bean = newFilterRegistrationBean(new CorsFilter(source)); bean.setOrder(0); return bean;} 5. 测试新建另外一个 web 项目，此项目端口为 9000，即我们前面设置的 origin ，而 api 项目的端口为 8080。 其中主要代码如下： public/hello.js 12345678$(document).ready(function () { $.ajax({ url: \"http://localhost:8080/hello\", }).then(function (data, status, jqxhr) { $(\".greeting-test\").append(data); console.log(jqxhr); });}); public/index.html 1234567891011121314&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;Hello CORS&lt;/title&gt; &lt;script src=\"https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js\"&gt;&lt;/script&gt; &lt;script src=\"hello.js\"&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div&gt; &lt;p class=\"greeting-test\"&gt;Hello&lt;/p&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 请求成功时即可看到返回结果。 1Hello world 参考链接： 跨域资源共享 CORS 详解 —— 阮一峰 《Enabling Cross Origin Requests for a RESTful Web Service》","link":"/2020/04/11/spring-boot-crossorign/"}],"tags":[{"name":"grafana","slug":"grafana","link":"/tags/grafana/"},{"name":"node_exporter","slug":"node-exporter","link":"/tags/node-exporter/"},{"name":"tcp","slug":"tcp","link":"/tags/tcp/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"spring boot","slug":"spring-boot","link":"/tags/spring-boot/"},{"name":"java","slug":"java","link":"/tags/java/"}],"categories":[{"name":"grafana","slug":"grafana","link":"/categories/grafana/"},{"name":"linux","slug":"linux","link":"/categories/linux/"},{"name":"spring boot","slug":"spring-boot","link":"/categories/spring-boot/"}]}